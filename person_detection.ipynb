{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6YEXmI_cOg5M",
        "gqSl6AYxOyuO",
        "JnRR5-mc1yId",
        "AVCaFRhk3rF1",
        "lyI3zlHU4VoN"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports and installations**"
      ],
      "metadata": {
        "id": "6YEXmI_cOg5M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gftIx3BHM-wt",
        "outputId": "b6261025-6240-4aa8-b680-eef959a92645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "lfXIvB9FNUzA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dfc5f1-8c71-4193-c58a-2625335e3246"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.1.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO, RTDETR\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "JVxbxNNXNYTX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RTDETR('rtdetr-l.pt')"
      ],
      "metadata": {
        "id": "saaltWt2NbPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d98c11-e6c2-43ab-9e58-ff95f9875329"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/rtdetr-l.pt to 'rtdetr-l.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63.4M/63.4M [00:00<00:00, 227MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functions and classes**"
      ],
      "metadata": {
        "id": "gqSl6AYxOyuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tracker:\n",
        "    \"\"\"\n",
        "      Tracker class to keep track of object IDs and their positions.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize the Tracker object.\n",
        "\n",
        "        Attributes:\n",
        "            center_points (dict): Dictionary to store the center positions of the objects.\n",
        "            id_count (int): Counter to keep track of the IDs.\n",
        "        \"\"\"\n",
        "        self.center_points = {}\n",
        "        self.id_count = 0\n",
        "\n",
        "    def update(self, objects_rect):\n",
        "        \"\"\"\n",
        "        Update the tracker with new object bounding boxes.\n",
        "\n",
        "        Parameters:\n",
        "            objects_rect (List[Tuple[int, int, int, int]]): List of object bounding boxes\n",
        "                (x, y, width, height) for the current frame.\n",
        "\n",
        "        Returns:\n",
        "            List[List[int]]: List of object bounding boxes with assigned IDs\n",
        "                (x, y, width, height, object_id).\n",
        "        \"\"\"\n",
        "        # Objects boxes and ids\n",
        "        objects_bbs_ids = []\n",
        "\n",
        "        # Get center point of new object\n",
        "        for rect in objects_rect:\n",
        "            x, y, w, h = rect\n",
        "            cx = (x + x + w) // 2\n",
        "            cy = (y + y + h) // 2\n",
        "\n",
        "            # Find out if that object was detected already\n",
        "            same_object_detected = False\n",
        "            for id, pt in self.center_points.items():\n",
        "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
        "\n",
        "                if dist < 35:\n",
        "                    self.center_points[id] = (cx, cy)\n",
        "                    objects_bbs_ids.append([x, y, w, h, id])\n",
        "                    same_object_detected = True\n",
        "                    break\n",
        "\n",
        "            # New object is detected we assign the ID to that object\n",
        "            if same_object_detected is False:\n",
        "                self.center_points[self.id_count] = (cx, cy)\n",
        "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
        "                self.id_count += 1\n",
        "\n",
        "        # Clean the dictionary by center points to remove IDS not used anymore\n",
        "        new_center_points = {}\n",
        "        for obj_bb_id in objects_bbs_ids:\n",
        "            _, _, _, _, object_id = obj_bb_id\n",
        "            center = self.center_points[object_id]\n",
        "            new_center_points[object_id] = center\n",
        "\n",
        "        # Update dictionary with IDs not used removed\n",
        "        self.center_points = new_center_points.copy()\n",
        "        return objects_bbs_ids"
      ],
      "metadata": {
        "id": "03m9IQ5WPfgZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def capture_input_video(input_path: str) -> cv2.VideoCapture:\n",
        "    \"\"\"\n",
        "    Capture input video from the specified path.\n",
        "\n",
        "    Parameters:\n",
        "        input_path (str): Path to the input video file.\n",
        "\n",
        "    Returns:\n",
        "        cv2.VideoCapture: VideoCapture object for the input video.\n",
        "    \"\"\"\n",
        "    return cv2.VideoCapture(input_path)"
      ],
      "metadata": {
        "id": "m5n3fLtuG8A1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_output_video(input_video: cv2.VideoCapture, output_path: str) -> cv2.VideoWriter:\n",
        "    \"\"\"\n",
        "    Create an output video writer object.\n",
        "\n",
        "    Parameters:\n",
        "        input_video (cv2.VideoCapture): VideoCapture object for the input video.\n",
        "        output_path (str): Path to save the output video file.\n",
        "\n",
        "    Returns:\n",
        "        cv2.VideoWriter: VideoWriter object for the output video.\n",
        "    \"\"\"\n",
        "    fps = input_video.get(cv2.CAP_PROP_FPS)\n",
        "    frame_width = int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    return cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))"
      ],
      "metadata": {
        "id": "pXVi-hjeG79O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame(frame: np.ndarray, model: object, task: str, threshold: float, tracker: Tracker, specific_area: List = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Process a single frame of the video.\n",
        "\n",
        "    Parameters:\n",
        "        frame (numpy.ndarray): Input frame to be processed.\n",
        "        model (object): Object representing the model used for prediction.\n",
        "        task (str): Task to be performed ('bounding_box', 'all_area', 'specific_area').\n",
        "        threshold (float): Threshold value for confidence.\n",
        "        tracker (Tracker): Object representing the tracker.\n",
        "        specific_area (numpy.ndarray, optional): Area for specific area task.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing processed frame and count of people (int).\n",
        "    \"\"\"\n",
        "    results = model.predict(frame, classes=0, conf=threshold)\n",
        "    a = results[0].boxes.data.cpu()\n",
        "    px = pd.DataFrame(a).astype(\"float\")\n",
        "    bboxes = []\n",
        "    counter = 0\n",
        "\n",
        "    for index, row in px.iterrows():\n",
        "        x1, y1, x2, y2, _, d = map(int, row)\n",
        "        bboxes.append([x1, y1, x2, y2])\n",
        "\n",
        "    bbox_id = tracker.update(bboxes)\n",
        "    for bbox in bbox_id:\n",
        "        x1, y1, x2, y2, id = bbox\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "\n",
        "        if task == 'specific_area' and specific_area is not None:\n",
        "            results = cv2.pointPolygonTest(np.array(specific_area, np.int32), ((cx, cy)), False)\n",
        "            if results >= 0:\n",
        "                counter += 1\n",
        "\n",
        "    return frame, counter if task == 'specific_area' else len(bboxes)\n"
      ],
      "metadata": {
        "id": "fn8ftpmQG77R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(input_path: str = '/content/drive/MyDrive/test.mp4', output_name: str = 'bbox_0.55_rtdetrl.mp4', task: str = 'bounding_box', threshold: float = 0.55) -> None:\n",
        "    \"\"\"\n",
        "    Main function to process the input video.\n",
        "\n",
        "    Parameters:\n",
        "        input_path (str): Path to the input video file.\n",
        "        output_name (str): Name to save the output video file.\n",
        "        task (str): Task to be performed ('bounding_box', 'all_area', 'specific_area').\n",
        "        threshold (float): Threshold value for confidence.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the task argument does not match with the allowed values.\n",
        "    \"\"\"\n",
        "    if task not in ['bounding_box', 'all_area', 'specific_area']:\n",
        "        raise ValueError(\"Invalid task. Allowed values: 'bounding_box', 'all_area', 'specific_area'\")\n",
        "\n",
        "    cap = capture_input_video(input_path)\n",
        "    output_video_path = f'/content/drive/MyDrive/{output_name}'\n",
        "    out = create_output_video(cap, output_video_path)\n",
        "    tracker = Tracker()\n",
        "    specific_area = [(250, 80), (380, 80), (380, 160), (250, 160)]\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame, counter = process_frame(frame, model, task, threshold, tracker, specific_area)\n",
        "\n",
        "        if task == 'all_area':\n",
        "            cv2.putText(frame, f'Number of people: {counter}', (10, 15), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1)\n",
        "        elif task == 'specific_area':\n",
        "            cv2.putText(frame, f'Number of people in specific area: {counter}', (10, 15), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 255), 1)\n",
        "\n",
        "        out.write(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "glQboPJMHA_E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step1: Bounding Box**"
      ],
      "metadata": {
        "id": "JnRR5-mc1yId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(input_path='/content/drive/MyDrive/test.mp4', output_name='bbox_0.55_rtdetrl.mp4', task='bounding_box', threshold=0.55)"
      ],
      "metadata": {
        "id": "heZZySEMJi3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step2: count people**"
      ],
      "metadata": {
        "id": "AVCaFRhk3rF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(input_path='/content/drive/MyDrive/test.mp4', output_name='out_conf_0.55_all_rtdetrl.mp4', task='all_area', threshold=0.55)"
      ],
      "metadata": {
        "id": "6VGaYVBZKUk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step3: count people in specific area**"
      ],
      "metadata": {
        "id": "lyI3zlHU4VoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(input_path='/content/drive/MyDrive/test.mp4', output_name='specific_area_0.55_rtdetrl.mp4', task='specific_area', threshold=0.55)"
      ],
      "metadata": {
        "id": "PqMi_apIEeit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}